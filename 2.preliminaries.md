本章为学习深度学习的前置知识/基本技能。这些知识/技能将会在未来你所有接触的深度学习或机器学习内容中陪伴着你，就像吃饭要先会使用筷子一样，基本的知识技能是不可或缺的。  
- 数据操作
- 数据预处理
- 线性代数
- 微积分
- 自动微分
- 概率

---
## 数据操作
**张量（Tensor）** 是深度学习中表示数据的核心概念。  
张量可以理解为向量的推广，可以表示更高维度的向量，是一个多维数组，可以理解为多个向量的堆叠。在实际表示中都是以矩阵/多维数组的形式出现。  
- 0阶张量是标量（数值）
- 1阶张量是向量
- 2阶张量是矩阵（多个向量）
- 3阶张量是一组矩阵

下面为PyTorch中对于张量的操作。

### 基础
- 创建行向量：`torch.arange(num)`
- 访问张量形状：`.shape`
- 张量中元素的总数：`.numel()`
- 改变张量的形状而不改变元素数量和元素值（张量大小不变）：`.reshape(size)`(如:`x.reshape(3, 4)`)。不一定要指定改变形状的每一个维度，在知道其他维度后可自动计算。
- 创建元素全零张量：`torch.zeros(size)`
- 创建元素全1张量：`torch.ones(size)`
- 创建元素符合标准高斯分布的张量：`torch.randn(size)`
- 创建指定数值的张量：`torch.tensor([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])`

### 运算符
张量是可以进行各种运算的。
- 标准算术运算（对于同一形状两个张量逐元素操作）：+、-、*、/、**、%
- 其他逐元素运算：
  - 绝对值：`torch.abs(a-b)`
  - 比较：`a.eq(b)`。(eq,ne,lt,le,gt,ge)
  - 逻辑：`torch.logical_and(a, b)`。(logical_and, logical_or, logical_not)
  - 指数对数：`torch.exp(a)`, `torch.log(b)`
  - 三角函数：`torch.sin(a)`。(sin,cos,tan,asin,acos,atan)
  - 最大值最小值：`torch.fmax(a, b)`。(fmax, fmin)
  - 克隆：`a.copy_(b)`
  - 自定义函数：`c = torch.where(a > 2, a, b)`
- 张量连接（concatenate）：`torch.cat((tensor1, tensor2), dim=?)`
- 逻辑运算构建二元张量：`X==Y`
- 所有元素求和：`X.sum()`

### broadcasting mechanism
对形状不同的张量进行操作。
工作方式为：
1. 通过适当的方式复制元素拓展数组，使得两个张量具有相同的形状（可以理解为补齐）
2. 按元素操作
这个广播机制是torch内部已经实现了的。例如:
a：$3 \times 1$
b: $1 \times 2$
a + b: $3 \times 2$

### 索引和切片
和Python中的数组索引操作相同

### 节省内存
Python中的一些操作是为新结果分配新的内存，这样造成了内存消耗，深度学习/机器学习往往涉及大数据处理，节省内存是必要的。不必要总是分配新内存，在旧位置更新即可，而且新内存分配会导致相同变量名的数据不同产生冲突。  
- 使用切片操作将新结果分配给原始变量
- 使用`+=`等优化后的简洁操作可以减少内存开销

### 转换为其他Python对象
tensor可以转换为其他架构/库的数据类型。也可以使用Python的内置函数`item()`等转换

---
## 数据预处理
原始数据往往是不同的数据格式或者非张量格式，需要进行预处理。数据预处理尝试用`pandas`库。

### 读取数据集
- 读取CSV文件
    ```python
    import pandas as pd
    data = pd.read_csv('dataset.csv')
    ```
- 读取Excel文件
    ```python
    import pandas as pd
    data = pd.read_excel('dataser.xlsx', sheet_name='Sheet1')
    ```
- 读取图像数据
    ```python
    import cv2
    image = cv2.imread('image.jpg')
    ```
- 读取大型数据集
  使用`torch.utils.data.Dataset`和`torch.utils.data.DataLoader`
    ```python
    import torch
    from torch.utils.data import Dataset, DataLoader

    class CustomDataset(Dataset):
        def __init__(self, data):
            self.data = data
      
        def __len__(self):
            return len(self.data)
      
        def __getitem__(self, index):
            return self.data[index]

    # 创建自定义数据集实例
    dataset = CustomDataset(data)

    # 创建 DataLoader 加载数据
    dataloader = DataLoader(dataset, batch_size=64, shuffle=True, num_workers=4)
    ```

### 处理缺失值
- 插值法：`fillna()`。一般插入`NaN`或数据均值
- 删除法：`dropna()`。

### 转换为张量
数值类型可以转换为张量`torch.tensor(dataset.to_numpy(dtype=int))`

---
## 线性代数
请确保你学习过线性代数这门课，学过忘了都可以，起码有印象。若没有学过，推荐[MIT18.06:Linear Algebra](https://csdiy.wiki/%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/MITLA/)
请详细阅读[2.3.线性代数](https://zh-v2.d2l.ai/chapter_preliminaries/linear-algebra.html)和[22.1.线性代数运算的在线附录](https://d2l.ai/chapter_appendix-mathematics-for-deep-learning/geometry-linear-algebraic-ops.html)
  
- 转置：`.T`
- 克隆：`.clone()`
- 点积：`torch.dot(tensor1, tensor2)`
- 向量积：`torch.mv(tensor1, tensor2)`
- 矩阵乘法：`torch.mm(tensor1, tensor2)`
- 范数：`torch.norm(tensor)`

**注意：PyTroch中对于张量相关的线性代数运算有不同的运算函数方法，不同的方法会存在细微的差别，请查阅PyTorch的官方文档学习** 

---
## 微积分
请确保你学习过微积分这门课，学过了忘了都可以，起码有印象。若没学过，推荐[Bilibili宋浩老师的课程](https://www.bilibili.com/video/BV1Eb411u7Fw)和[3BlueBrown的视频](https://www.bilibili.com/video/BV1qW411N7FU)。需要注意的是，微积分是一门基础而重要的课程，本人在学习过程中忽视了微积分的重要性，这也影响了自己后续的学习。在这劝告每一位朋友，学好微积分、线性代数、概率论与数理统计这三门基础数学课，不要以考试为目的。

核心概念：
  - 导数和微分
  - 偏导数
  - 梯度
  - 链式法则

---
## 自动微分
手动计算导数是很艰难的，而且深度学习中会涉及大量的梯度计算。深度学习框架中通过自动微分（automatic differentiation）加快求导。

- 自动微分计算一个函数在指定值上的导数。是一种用于计算导数的数学技术，用于有效地应用反向传播算法，利用链式法则来计算复杂函数梯度的方法。主要包括：
  - 正向传播
  - 反向传播
  - 链式法则
  - 梯度计算

- 计算图是一个有向图。节点表示变量，边表示操作。
  - 将代码分解成操作子
  - 将计算表示成一个无环图
  - 有向性：输入到输出
  - 动态性：梯度更新
  
通过自动微分和计算图就可以实现高效大量的梯度计算了。

---
## 概率
概率可以说是在机器学习/深度学习中无比重要的一部分了，概率在预测问题，图像识别，强化学习，扩散模型等方方面面渗透进了人工智能里面。

首先，请确保你学习过概率论与数理统计这门课，学过了忘了都可以，起码有印象。若没学过，请通过网络找到相关的课程学习。目前没有推荐课程，因为我概率论也学得不好。

