损失函数：对于每一个训练样本，损失函数计算了预测输出与真实输出之间的差异。损失函数的设计取决于问题类型（如回归或分类）。

误差：是损失函数在所有训练样本上的平均，它提供了模型在训练数据集上的总体性能度量。误差越小，表示模型的预测结果越接近真实数据。

---
## 1. 训练误差
训练误差是训练过程中在训练数据集上的性能评估标准。训练误差也就是模型在训练数据集上的性能表现，是体现出**模型对数据的拟合程度**，也叫拟合误差。  
如果模型在训练数据上表现很好，就是训练误差很小，但是测试误差很差，就是出现了overfitting。

## 2. 测试误差
测试误差是测试过程中在测试数据集上的性能评估标准。测试误差就是在模型没有见过的数据上的性能表现，是体现出**模型的泛化能力**，也叫泛化误差。    
如果模型在测试数据上表现良好，测试误差和训练误差解决，说明模型有较好的泛化能力。

## 3. 评估方法
误差一般通过损失函数的值来表示，泛化误差通常以交叉验证的结果表示。  
下面是误差的一些常见的评估方法，其中MSE，MAE，交叉熵就是我们常用的损失函数：
1. **均方误差（Mean Squared Error，MSE）**：用于回归问题，表示实际值与预测值之间的平方差的平均值。  
	数学表示：$MSE = \frac{1}{n} \sum_{i=1}^{n}(y_i - \hat{y}_i)^2$  
   其中：
   - $n$ 是样本数量。
   - $y_i$ 是第 $i$ 个样本的实际目标值。
   - $\hat{y}_i$ 是第 $i$ 个样本的模型预测值。
    
2. **平均绝对误差（Mean Absolute Error，MAE）**：用于回归问题，表示实际值与预测值之间的绝对差的平均值。  
	数学表示：$MAE = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i|$
    
3. **交叉熵（Cross-Entropy）**：用于分类问题，衡量模型对不同类别的分类性能。  
	交叉熵通常用于二分类问题，数学表示为：  
   $CE = -\frac{1}{n} \sum_{i=1}^{n} [y_i \log(\hat{y}_i) + (1 - y_i) \log(1 - \hat{y}_i)]$  
   其中：  
   - $n$ 是样本数量。
   - $y_i$ 是第 $i$ 个样本的实际标签（0或1）。
   - $\hat{y}_i$ 是第 $i$ 个样本的模型预测的概率值（0到1之间）。
    
4. **准确率（Accuracy）**：用于分类问题，表示模型正确分类的样本占总样本数的比例。  
	数学表示：$Accuracy = \frac{\text{正确分类的样本数}}{\text{总样本数}}$
    
5. **精确度（Precision）** 和**召回率（Recall）**：用于二分类问题，Precision 表示模型正确预测正类别的比例，Recall 表示模型正确检测正类别的比例。  
	数学表示：$Precision = \frac{\text{True Positives}}{\text{True Positives} + \text{False Positives}}$
    $Recall = \frac{\text{True Positives}}{\text{True Positives} + \text{False Negatives}}$
6. **F1分数（F1 Score）**：综合考虑 Precision 和 Recall，是一个平衡的性能指标。  
	数学表示：$F1 = \frac{2 \times \text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}$

